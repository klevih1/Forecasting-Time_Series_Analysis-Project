{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e581a302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 CSV files. Starting processing...\n",
      "  -> Added 5812 rows from waqi-covid19-airqualitydata-2015H1.csv\n",
      "  -> Added 5883 rows from waqi-covid19-airqualitydata-2016H1.csv\n",
      "  -> Added 5527 rows from waqi-covid19-airqualitydata-2017H1.csv\n",
      "  -> Added 7566 rows from waqi-covid19-airqualitydata-2018H1.csv\n",
      "  -> Added 6097 rows from waqi-covid19-airqualitydata-2019Q1.csv\n",
      "  -> Added 6239 rows from waqi-covid19-airqualitydata-2019Q2.csv\n",
      "  -> Added 6617 rows from waqi-covid19-airqualitydata-2019Q3.csv\n",
      "  -> Added 6590 rows from waqi-covid19-airqualitydata-2019Q4.csv\n",
      "  -> Added 6117 rows from waqi-covid19-airqualitydata-2020Q1.csv\n",
      "  -> Added 6803 rows from waqi-covid19-airqualitydata-2020Q2.csv\n",
      "  -> Added 6684 rows from waqi-covid19-airqualitydata-2020Q3.csv\n",
      "  -> Added 6730 rows from waqi-covid19-airqualitydata-2020Q4.csv\n",
      "  -> Added 6701 rows from waqi-covid19-airqualitydata-2021Q1.csv\n",
      "  -> Added 6726 rows from waqi-covid19-airqualitydata-2021Q2.csv\n",
      "  -> Added 6735 rows from waqi-covid19-airqualitydata-2021Q3.csv\n",
      "  -> Added 6495 rows from waqi-covid19-airqualitydata-2021Q4.csv\n",
      "  -> Skipping waqi-covid19-airqualitydata-2022Q1.csv: Could not find columns ['Date', 'City', 'Specie']\n",
      "  -> Added 6483 rows from waqi-covid19-airqualitydata-2022Q2.csv\n",
      "  -> Added 6478 rows from waqi-covid19-airqualitydata-2022Q3.csv\n",
      "  -> Added 6566 rows from waqi-covid19-airqualitydata-2022Q4.csv\n",
      "  -> Added 6601 rows from waqi-covid19-airqualitydata-2023Q1.csv\n",
      "  -> Added 6632 rows from waqi-covid19-airqualitydata-2023Q2.csv\n",
      "  -> Added 3189 rows from waqi-covid19-airqualitydata-2023Q3.csv\n",
      "  -> Added 3221 rows from waqi-covid19-airqualitydata-2023Q4.csv\n",
      "  -> Added 49234 rows from waqi-covid19-airqualitydata-2025.csv\n",
      "\n",
      "Consolidating and saving...\n",
      "Success! Saved 191726 rows to c:\\Users\\klevi\\Desktop\\Time Series Analysis\\Air_Quality_Index-CAPSTONE_PROJECT\\data\\processed\\filtered_data.parquet\n",
      "Cities in dataset: ['Beijing' 'Berlin' 'London' 'Paris' 'Tokyo']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Specie",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "variance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e00b9faa-83de-4ea3-bba6-f91284eaa8a2",
       "rows": [
        [
         "3992",
         "2014-12-29 00:00:00",
         "CN",
         "Beijing",
         "co",
         "429",
         "2.8",
         "90.4",
         "32.6",
         "4266.95"
        ],
        [
         "3753",
         "2014-12-29 00:00:00",
         "CN",
         "Beijing",
         "no2",
         "432",
         "2.4",
         "114.2",
         "51.0",
         "3901.05"
        ],
        [
         "4357",
         "2014-12-29 00:00:00",
         "CN",
         "Beijing",
         "o3",
         "354",
         "0.9",
         "39.5",
         "3.7",
         "932.37"
        ],
        [
         "4298",
         "2014-12-29 00:00:00",
         "CN",
         "Beijing",
         "pm10",
         "376",
         "22.0",
         "735.0",
         "118.0",
         "63652.9"
        ],
        [
         "3685",
         "2014-12-29 00:00:00",
         "CN",
         "Beijing",
         "pm25",
         "421",
         "18.0",
         "564.0",
         "190.0",
         "133562.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Specie</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>CN</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>co</td>\n",
       "      <td>429</td>\n",
       "      <td>2.8</td>\n",
       "      <td>90.4</td>\n",
       "      <td>32.6</td>\n",
       "      <td>4266.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>CN</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>no2</td>\n",
       "      <td>432</td>\n",
       "      <td>2.4</td>\n",
       "      <td>114.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3901.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>CN</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>o3</td>\n",
       "      <td>354</td>\n",
       "      <td>0.9</td>\n",
       "      <td>39.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>932.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>CN</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>pm10</td>\n",
       "      <td>376</td>\n",
       "      <td>22.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>63652.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>CN</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>pm25</td>\n",
       "      <td>421</td>\n",
       "      <td>18.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>133562.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Country     City Specie  count   min    max  median   variance\n",
       "3992 2014-12-29      CN  Beijing     co    429   2.8   90.4    32.6    4266.95\n",
       "3753 2014-12-29      CN  Beijing    no2    432   2.4  114.2    51.0    3901.05\n",
       "4357 2014-12-29      CN  Beijing     o3    354   0.9   39.5     3.7     932.37\n",
       "4298 2014-12-29      CN  Beijing   pm10    376  22.0  735.0   118.0   63652.90\n",
       "3685 2014-12-29      CN  Beijing   pm25    421  18.0  564.0   190.0  133562.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import display\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TARGET_CITIES = [\"London\", \"Paris\", \"Beijing\", \"Tokyo\", \"Berlin\"]\n",
    "\n",
    "# Path logic: We are in 'src/', so we go up one level to reach project root, then into 'data/'\n",
    "PROJECT_ROOT = os.path.dirname(os.getcwd())\n",
    "RAW_DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "OUTPUT_FILE = os.path.join(PROJECT_ROOT, \"data\", \"processed\", \"filtered_data.parquet\")\n",
    "\n",
    "# 1. FIND ALL CSV FILES\n",
    "csv_files = glob.glob(os.path.join(RAW_DATA_DIR, \"*.csv\"))\n",
    "all_dataframes = []\n",
    "\n",
    "if not csv_files:\n",
    "    print(f\"Error: No CSV files found in {RAW_DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"Found {len(csv_files)} CSV files. Starting processing...\")\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # The WAQI datasets often have 4 lines of comments at the top.\n",
    "        # We use skiprows=4 to start reading at the header line.\n",
    "        df = pd.read_csv(file_path, skiprows=4)\n",
    "            \n",
    "        # Clean column names (remove hidden spaces)\n",
    "        df.columns = df.columns.str.strip()\n",
    "            \n",
    "        # Validate required columns exist after skipping headers\n",
    "        required = ['Date', 'City', 'Specie']\n",
    "        if all(col in df.columns for col in required):\n",
    "            # Normalize city names\n",
    "            df['City'] = df['City'].astype(str).str.title()\n",
    "            filtered_chunk = df[df['City'].isin(TARGET_CITIES)].copy()\n",
    "                \n",
    "            if not filtered_chunk.empty:\n",
    "                all_dataframes.append(filtered_chunk)\n",
    "                print(f\"  -> Added {len(filtered_chunk)} rows from {filename}\")\n",
    "            else:\n",
    "                print(f\"  -> Skipping {filename}: Could not find columns {required}\")\n",
    "\n",
    "\n",
    "    # 2. CONSOLIDATE AND SAVE\n",
    "    if all_dataframes:\n",
    "        print(\"\\nConsolidating and saving...\")\n",
    "        final_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        \n",
    "        # Ensure Date is in datetime format\n",
    "        final_df['Date'] = pd.to_datetime(final_df['Date'])\n",
    "        \n",
    "        # Sort chronologically\n",
    "        final_df = final_df.sort_values(by=['City', 'Date', 'Specie'])\n",
    "\n",
    "        # Create output directory\n",
    "        os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "        \n",
    "        # Save as Parquet\n",
    "        final_df.to_parquet(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"Success! Saved {len(final_df)} rows to {OUTPUT_FILE}\")\n",
    "        print(f\"Cities in dataset: {final_df['City'].unique()}\")\n",
    "        display(final_df.head())\n",
    "    else:\n",
    "        print(\"\\nNo matching data found for target cities. Check if the city names in CSV match your list.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
